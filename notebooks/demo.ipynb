{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Logistics Intelligence Hub — Demo\n",
    "\n",
    "This notebook demonstrates the core capabilities of the RAG pipeline:\n",
    "1. Document ingestion and parsing\n",
    "2. Semantic chunking with parent-child indexing\n",
    "3. PII masking\n",
    "4. Hybrid search (BM25 + vector)\n",
    "5. End-to-end query answering with source attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from src.processing.chunking import SemanticChunker\n",
    "from src.processing.pii_masking import PIIMasker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sample Supply Chain Documents\n",
    "\n",
    "We'll create sample documents that mimic real logistics data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_docs = [\n",
    "    Document(\n",
    "        page_content=\"\"\"\n",
    "Global Logistics Quarterly Report — Q3 2024\n",
    "\n",
    "Ocean Freight Summary:\n",
    "Ocean freight rates from Shanghai to Rotterdam have increased by 15% compared to Q2,\n",
    "driven by Red Sea diversions and increased demand from European importers. Average\n",
    "transit time is now 35 days via the Cape of Good Hope route, compared to 25 days\n",
    "through the Suez Canal. Container availability remains tight with equipment imbalances\n",
    "persisting across major trade lanes.\n",
    "\n",
    "The Shanghai Containerized Freight Index (SCFI) reached 2,847 points, up from 2,150\n",
    "in Q2. Spot rates for 40ft containers on the Asia-Europe route averaged $4,200 per TEU.\n",
    "\n",
    "Air Cargo Summary:\n",
    "Air cargo volumes grew 8% year-over-year with strong demand from e-commerce and\n",
    "pharmaceutical sectors. Rate per kg from Hong Kong to Los Angeles averaged $4.85,\n",
    "up from $4.20 in Q2. Capacity constraints at major hubs including Dubai (DXB) and\n",
    "Singapore (SIN) contributed to rate pressures.\n",
    "\n",
    "| Route | Mode | Transit Days | Rate Change Q/Q | Volume Change Y/Y |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| Shanghai-Rotterdam | Ocean | 35 | +15% | +5% |\n",
    "| Shenzhen-Los Angeles | Ocean | 18 | +12% | +8% |\n",
    "| Hong Kong-LAX | Air | 2 | +15.5% | +8% |\n",
    "| Dubai-London | Air | 1 | +10% | +6% |\n",
    "| Singapore-Sydney | Ocean | 12 | +8% | +3% |\n",
    "\"\"\",\n",
    "        metadata={\"source\": \"logistics_report_q3_2024.pdf\", \"page\": 1}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"\"\"\n",
    "Compliance & Customs Update — October 2024\n",
    "\n",
    "EU Carbon Border Adjustment Mechanism (CBAM):\n",
    "Starting January 2026, importers must purchase certificates for embedded carbon\n",
    "in goods including steel, cement, aluminum, fertilizers, and electricity. During\n",
    "the transitional phase (Oct 2023 - Dec 2025), importers must report embedded\n",
    "emissions without purchasing certificates.\n",
    "\n",
    "Key action items:\n",
    "- Map all in-scope product categories against HS codes\n",
    "- Collect verified emissions data from suppliers\n",
    "- Register in the CBAM transitional registry\n",
    "- Prepare for certificate purchasing starting 2026\n",
    "\n",
    "US Trade Compliance:\n",
    "New Section 301 tariff increases effective September 2024:\n",
    "- Electric vehicles from China: 100% (up from 25%)\n",
    "- Solar cells: 50% (up from 25%)\n",
    "- Steel and aluminum: 25% (no change)\n",
    "- Lithium-ion batteries: 25% (up from 7.5%)\n",
    "\"\"\",\n",
    "        metadata={\"source\": \"compliance_update_oct2024.pdf\", \"page\": 1}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"\"\"\n",
    "Warehouse Operations Report — Southeast Asia Hub\n",
    "\n",
    "Contact: John Smith (john.smith@globallogistics.com), +65-9123-4567\n",
    "Container Reference: MSCU7654321\n",
    "Customs Declaration: MRN98765432109876\n",
    "\n",
    "Inventory Levels:\n",
    "The Singapore distribution center currently holds 45,000 SKUs across 3 warehouse\n",
    "zones. Average pick-and-pack time is 4.2 minutes per order, with a 99.7% accuracy\n",
    "rate. Cold chain storage utilization is at 87%, approaching capacity limits.\n",
    "\n",
    "Key Metrics (September 2024):\n",
    "- Inbound receipts: 12,450 containers\n",
    "- Outbound shipments: 11,890 containers\n",
    "- Average dwell time: 3.8 days\n",
    "- Damage rate: 0.12%\n",
    "- On-time dispatch: 96.5%\n",
    "\"\"\",\n",
    "        metadata={\"source\": \"warehouse_ops_sea_sep2024.pdf\", \"page\": 1}\n",
    "    )\n",
    "]\n",
    "\n",
    "print(f\"Loaded {len(sample_docs)} sample documents\")\n",
    "for doc in sample_docs:\n",
    "    print(f\"  - {doc.metadata['source']}: {len(doc.page_content)} chars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. PII Masking\n",
    "\n",
    "Before processing, we mask personally identifiable information and logistics-specific identifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masker = PIIMasker()\n",
    "\n",
    "# Demonstrate on the warehouse document (contains PII)\n",
    "warehouse_doc = sample_docs[2]\n",
    "result = masker.mask(warehouse_doc.page_content)\n",
    "\n",
    "print(\"=== Entities Detected ===\")\n",
    "for entity in result.entities_found:\n",
    "    print(f\"  {entity['entity_type']}: score={entity['score']}\")\n",
    "\n",
    "print(\"\\n=== Entity Mapping (for audit) ===\")\n",
    "for placeholder, original in result.entity_mapping.items():\n",
    "    print(f\"  {placeholder} → {original}\")\n",
    "\n",
    "print(\"\\n=== Masked Text (first 500 chars) ===\")\n",
    "print(result.masked_text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Semantic Chunking\n",
    "\n",
    "Documents are split into parent chunks (for context) and child chunks (for retrieval), with tables preserved intact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunker = SemanticChunker(\n",
    "    parent_chunk_size=1000,\n",
    "    child_chunk_size=400,\n",
    "    child_chunk_overlap=50,\n",
    ")\n",
    "\n",
    "# Apply PII masking first\n",
    "masked_docs = []\n",
    "for doc in sample_docs:\n",
    "    mask_result = masker.mask(doc.page_content)\n",
    "    masked_docs.append(Document(\n",
    "        page_content=mask_result.masked_text,\n",
    "        metadata=doc.metadata\n",
    "    ))\n",
    "\n",
    "chunk_result = chunker.chunk_documents(masked_docs)\n",
    "\n",
    "print(f\"Parent chunks: {len(chunk_result.parent_chunks)}\")\n",
    "print(f\"Child chunks:  {len(chunk_result.child_chunks)}\")\n",
    "print(f\"\\n=== Sample Parent Chunk ===\")\n",
    "print(f\"Content ({len(chunk_result.parent_chunks[0].page_content)} chars):\")\n",
    "print(chunk_result.parent_chunks[0].page_content[:300])\n",
    "print(f\"\\nMetadata: {chunk_result.parent_chunks[0].metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show table chunks\n",
    "table_chunks = [c for c in chunk_result.parent_chunks if c.metadata.get(\"content_format\") == \"table\"]\n",
    "print(f\"Table chunks found: {len(table_chunks)}\")\n",
    "if table_chunks:\n",
    "    print(\"\\n=== Table Chunk ===\")\n",
    "    print(table_chunks[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify parent-child linkage\n",
    "parent_ids = {p.metadata[\"chunk_id\"] for p in chunk_result.parent_chunks}\n",
    "orphaned = [c for c in chunk_result.child_chunks if c.metadata[\"parent_id\"] not in parent_ids]\n",
    "print(f\"Total children: {len(chunk_result.child_chunks)}\")\n",
    "print(f\"Orphaned children (should be 0): {len(orphaned)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hybrid Search\n",
    "\n",
    "Index the chunks and run hybrid queries combining BM25 keyword matching with dense vector similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.processing.embeddings import EmbeddingService\n",
    "from src.vectorstore.hybrid_search import HybridSearchEngine\n",
    "\n",
    "# Initialize embedding service (uses sentence-transformers locally)\n",
    "embedding_service = EmbeddingService()\n",
    "print(f\"Embedding backend: {embedding_service.backend}\")\n",
    "\n",
    "# Create hybrid search engine\n",
    "search_engine = HybridSearchEngine(\n",
    "    embedding_service=embedding_service,\n",
    "    bm25_weight=0.3,\n",
    "    semantic_weight=0.7,\n",
    ")\n",
    "\n",
    "# Index all child chunks (used for retrieval)\n",
    "all_chunks = chunk_result.child_chunks\n",
    "search_engine.add_documents(all_chunks)\n",
    "print(f\"Indexed {len(all_chunks)} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run sample queries\n",
    "queries = [\n",
    "    \"What are the current ocean freight rates from Shanghai to Rotterdam?\",\n",
    "    \"What is the CBAM regulation and when does it take effect?\",\n",
    "    \"What is the average dwell time at the Singapore warehouse?\",\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    results = search_engine.search(query, top_k=3)\n",
    "    for i, (doc, score) in enumerate(results, 1):\n",
    "        print(f\"\\n  [{i}] Score: {score:.4f} | Source: {doc.metadata.get('source', 'unknown')}\")\n",
    "        print(f\"      {doc.page_content[:150]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. End-to-End RAG Query\n",
    "\n",
    "Full pipeline: query → hybrid retrieval → context expansion → LLM generation → source attribution.\n",
    "\n",
    "> **Note:** This cell requires an OpenAI API key configured in `.env`. Skip if running without API access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.rag.retriever import HybridRetriever\n",
    "from src.rag.chain import RAGChain\n",
    "\n",
    "# Add parent chunks to the engine for context expansion\n",
    "search_engine_full = HybridSearchEngine(embedding_service=embedding_service)\n",
    "all_indexed = chunk_result.parent_chunks + chunk_result.child_chunks\n",
    "search_engine_full.add_documents(all_indexed)\n",
    "\n",
    "retriever = HybridRetriever(\n",
    "    search_engine=search_engine_full,\n",
    "    top_k=5,\n",
    "    expand_to_parent=True,\n",
    ")\n",
    "\n",
    "try:\n",
    "    rag_chain = RAGChain(retriever=retriever)\n",
    "    \n",
    "    query = \"How have ocean freight rates changed and what routes are most affected?\"\n",
    "    response = rag_chain.invoke(query)\n",
    "    \n",
    "    print(f\"Query: {response.query}\")\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Answer:\\n{response.answer}\")\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Sources:\")\n",
    "    for src in response.sources:\n",
    "        print(f\"  - {src['source']} (page {src.get('page', 'N/A')})\")\n",
    "except Exception as e:\n",
    "    print(f\"LLM generation requires API key. Error: {e}\")\n",
    "    print(\"\\nRetrieval still works — showing retrieved context:\")\n",
    "    docs = retriever.invoke(\"How have ocean freight rates changed?\")\n",
    "    for i, doc in enumerate(docs, 1):\n",
    "        print(f\"\\n[{i}] {doc.metadata.get('source', 'unknown')}\")\n",
    "        print(f\"    {doc.page_content[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This demo showed the complete RAG pipeline:\n",
    "\n",
    "| Stage | Component | What it does |\n",
    "|-------|-----------|------|\n",
    "| Ingestion | `PDFLoader`, `ExcelLoader` | Parse documents with table awareness |\n",
    "| PII Masking | `PIIMasker` | Redact sensitive data with audit trail |\n",
    "| Chunking | `SemanticChunker` | Parent-child hierarchy with table preservation |\n",
    "| Search | `HybridSearchEngine` | BM25 + dense vector with RRF fusion |\n",
    "| RAG | `RAGChain` | LCEL chain with source attribution |\n",
    "| API | `FastAPI` | REST endpoints for production deployment |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
